{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.6\n",
    "test_size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data['data']\n",
    "target = data['target'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.hstack((dataset,target))\n",
    "np.random.shuffle(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "148                5.0               3.0                1.6               0.2   \n",
       "149                6.6               3.0                4.4               1.4   \n",
       "\n",
       "     target  \n",
       "148     0.0  \n",
       "149     1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data = pd.DataFrame(final_data)\n",
    "pd_data.columns= ['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)','target']\n",
    "pd_data = pd_data[(pd_data['target']==0) | (pd_data['target']==1)]\n",
    "pd_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 5), (40, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd_data.values\n",
    "\n",
    "train_data = final_data[:int(len(final_data)*train_size)]\n",
    "test_data = final_data[:int(len(final_data)*test_size)]\n",
    "\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 4), (60, 1), (40, 4), (40, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[:,:-1]\n",
    "y_train = train_data[:,-1:]\n",
    "\n",
    "\n",
    "X_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1:]\n",
    "\n",
    "\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(y,y_pred,x):\n",
    "    return np.dot(x.T,(y-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_grad(x):\n",
    "    return sigmoid(x)(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,y_pred):\n",
    "    cost = -np.mean((y*np.log(y_pred))+((1-y)*(np.log(1-y_pred))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0  Loss: 0.6931471805599454\n",
      "Epoch :  10  Loss: 0.45404404398342585\n",
      "Epoch :  20  Loss: 0.34501271812028766\n",
      "Epoch :  30  Loss: 0.2744144239464629\n",
      "Epoch :  40  Loss: 0.22630474203414064\n",
      "Epoch :  50  Loss: 0.19191878157005823\n",
      "Epoch :  60  Loss: 0.16632854516284812\n",
      "Epoch :  70  Loss: 0.14663856127660732\n",
      "Epoch :  80  Loss: 0.1310667624025375\n",
      "Epoch :  90  Loss: 0.11846834016980826\n",
      "Epoch :  100  Loss: 0.10807948743669037\n",
      "Epoch :  110  Loss: 0.09937350552077762\n",
      "Epoch :  120  Loss: 0.09197663368074177\n",
      "Epoch :  130  Loss: 0.08561693077445656\n",
      "Epoch :  140  Loss: 0.08009216356882747\n",
      "Epoch :  150  Loss: 0.07524901618894266\n",
      "Epoch :  160  Loss: 0.07096926136743102\n",
      "Epoch :  170  Loss: 0.06716033768620396\n",
      "Epoch :  180  Loss: 0.06374878853312708\n",
      "Epoch :  190  Loss: 0.06067560377790207\n",
      "Epoch :  200  Loss: 0.05789285362786187\n",
      "Epoch :  210  Loss: 0.055361217069271704\n",
      "Epoch :  220  Loss: 0.053048140575376816\n",
      "Epoch :  230  Loss: 0.050926448018229646\n",
      "Epoch :  240  Loss: 0.0489732783631883\n",
      "Epoch :  250  Loss: 0.047169264714777705\n",
      "Epoch :  260  Loss: 0.04549789329395868\n",
      "Epoch :  270  Loss: 0.043944998106142504\n",
      "Epoch :  280  Loss: 0.04249835903172242\n",
      "Epoch :  290  Loss: 0.04114737952788491\n",
      "Epoch :  300  Loss: 0.03988282617966221\n",
      "Epoch :  310  Loss: 0.03869661671603021\n",
      "Epoch :  320  Loss: 0.03758164630994498\n",
      "Epoch :  330  Loss: 0.03653164434889157\n",
      "Epoch :  340  Loss: 0.03554105562955221\n",
      "Epoch :  350  Loss: 0.034604941260919946\n",
      "Epoch :  360  Loss: 0.03371889557086482\n",
      "Epoch :  370  Loss: 0.032878976084948296\n",
      "Epoch :  380  Loss: 0.0320816442431973\n",
      "Epoch :  390  Loss: 0.03132371498432975\n",
      "Epoch :  400  Loss: 0.030602313689712866\n",
      "Epoch :  410  Loss: 0.0299148392649541\n",
      "Epoch :  420  Loss: 0.0292589323632676\n",
      "Epoch :  430  Loss: 0.028632447935008177\n",
      "Epoch :  440  Loss: 0.02803343143217216\n",
      "Epoch :  450  Loss: 0.027460098112963335\n",
      "Epoch :  460  Loss: 0.026910814985657762\n",
      "Epoch :  470  Loss: 0.02638408500756444\n",
      "Epoch :  480  Loss: 0.02587853321743476\n",
      "Epoch :  490  Loss: 0.025392894531011238\n",
      "Epoch :  500  Loss: 0.02492600297171499\n",
      "Epoch :  510  Loss: 0.02447678214347878\n",
      "Epoch :  520  Loss: 0.02404423678181287\n",
      "Epoch :  530  Loss: 0.023627445243436455\n",
      "Epoch :  540  Loss: 0.023225552815094756\n",
      "Epoch :  550  Loss: 0.022837765739215154\n",
      "Epoch :  560  Loss: 0.022463345868405604\n",
      "Epoch :  570  Loss: 0.022101605872923875\n",
      "Epoch :  580  Loss: 0.02175190493552724\n",
      "Epoch :  590  Loss: 0.021413644876849512\n",
      "Epoch :  600  Loss: 0.02108626666190699\n",
      "Epoch :  610  Loss: 0.02076924724470291\n",
      "Epoch :  620  Loss: 0.020462096713364814\n",
      "Epoch :  630  Loss: 0.020164355702941818\n",
      "Epoch :  640  Loss: 0.019875593047034075\n",
      "Epoch :  650  Loss: 0.019595403642921543\n",
      "Epoch :  660  Loss: 0.019323406507881793\n",
      "Epoch :  670  Loss: 0.01905924300701324\n",
      "Epoch :  680  Loss: 0.018802575235161\n",
      "Epoch :  690  Loss: 0.018553084537532055\n",
      "Epoch :  700  Loss: 0.018310470155323368\n",
      "Epoch :  710  Loss: 0.01807444798420633\n",
      "Epoch :  720  Loss: 0.017844749434843276\n",
      "Epoch :  730  Loss: 0.017621120385782157\n",
      "Epoch :  740  Loss: 0.017403320220106006\n",
      "Epoch :  750  Loss: 0.0171911209381208\n",
      "Epoch :  760  Loss: 0.016984306339168132\n",
      "Epoch :  770  Loss: 0.016782671266357765\n",
      "Epoch :  780  Loss: 0.01658602090864426\n",
      "Epoch :  790  Loss: 0.016394170155228826\n",
      "Epoch :  800  Loss: 0.01620694299776416\n",
      "Epoch :  810  Loss: 0.016024171976280872\n",
      "Epoch :  820  Loss: 0.01584569766514774\n",
      "Epoch :  830  Loss: 0.015671368195729552\n",
      "Epoch :  840  Loss: 0.01550103881271971\n",
      "Epoch :  850  Loss: 0.01533457146140735\n",
      "Epoch :  860  Loss: 0.015171834403389118\n",
      "Epoch :  870  Loss: 0.015012701858463555\n",
      "Epoch :  880  Loss: 0.014857053670648646\n",
      "Epoch :  890  Loss: 0.014704774996446504\n",
      "Epoch :  900  Loss: 0.014555756013644101\n",
      "Epoch :  910  Loss: 0.014409891649087585\n",
      "Epoch :  920  Loss: 0.01426708132400245\n",
      "Epoch :  930  Loss: 0.014127228715552938\n",
      "Epoch :  940  Loss: 0.013990241533445073\n",
      "Epoch :  950  Loss: 0.013856031310475624\n",
      "Epoch :  960  Loss: 0.01372451320602191\n",
      "Epoch :  970  Loss: 0.01359560582154771\n",
      "Epoch :  980  Loss: 0.013469231027276455\n",
      "Epoch :  990  Loss: 0.013345313799249914\n"
     ]
    }
   ],
   "source": [
    "dummy_train = np.hstack((np.ones((len(train_data),1)),X_train))\n",
    "weight = np.zeros((len(dummy_train[0]),1))\n",
    "lr = 0.001\n",
    "epoch = 1000\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    y_pred = sigmoid(np.dot(dummy_train,weight))\n",
    "    co = cost(y_train,y_pred)\n",
    "    gra = gradient(y_train,y_pred,dummy_train)\n",
    "    weight += lr*gra\n",
    "    \n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print('Epoch : ',i,' Loss:',co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30835434],\n",
       "       [-0.48807419],\n",
       "       [-1.70864701],\n",
       "       [ 2.7262654 ],\n",
       "       [ 1.17696908]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w):\n",
    "    sig = sigmoid(np.dot(x,w[1:])+w[0])\n",
    "    sig[sig > 0.5] = 1\n",
    "    sig[sig < 0.5] = 0\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict(X_test,weight),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lr=0.01,batch_size=None,epoch=10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.sigmoid(np.dot(self.train_data,self.params))\n",
    "            loss = self.cost(self.train_labels,y_pred)\n",
    "            \n",
    "            gra = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "            \n",
    "            self.params -= self.lr*gra\n",
    "            \n",
    "            if i%10 == 0:\n",
    "                print('Epoch : {}  Loss: {}'.format(i+1,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result >= 0.5 ] = 1\n",
    "        result[result < 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = logisticregression(X_train,y_train,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1  Loss: 0.6931471805599454\n",
      "Epoch : 11  Loss: 0.03011887563228673\n",
      "Epoch : 21  Loss: 0.0245683326731343\n",
      "Epoch : 31  Loss: 0.020811470246670714\n",
      "Epoch : 41  Loss: 0.018092057255623895\n",
      "Epoch : 51  Loss: 0.01602871851642816\n",
      "Epoch : 61  Loss: 0.014407255532154854\n",
      "Epoch : 71  Loss: 0.013097932564222243\n",
      "Epoch : 81  Loss: 0.012017497524929628\n",
      "Epoch : 91  Loss: 0.011110028303435075\n"
     ]
    }
   ],
   "source": [
    "logistic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
