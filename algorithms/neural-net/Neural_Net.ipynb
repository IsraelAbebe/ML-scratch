{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Net ",
      "provenance": [],
      "authorship_tag": "ABX9TyMIY14mu9zpmpdSi1LgasXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelAbebe/ml-algorithems-from-scratch/blob/master/algorithms/neural-net/Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GmE25gKPI8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a6a4e715-6d34-45f7-a525-0dbbb5590b67"
      },
      "source": [
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9_yQBm3PTzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "f4f1c3aa-0a14-4527-d82e-9b99450bc632"
      },
      "source": [
        "!unzip drive/My\\ Drive/data/data.zip \n",
        "# ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/data/data.zip\n",
            "   creating: data/\n",
            "   creating: data/mnist/\n",
            "   creating: data/mnist/raw/\n",
            "  inflating: data/mnist/raw/train-images-idx3-ubyte  \n",
            "  inflating: data/mnist/raw/train-labels-idx1-ubyte  \n",
            "  inflating: data/mnist/raw/t10k-images-idx3-ubyte  \n",
            "  inflating: data/mnist/raw/t10k-labels-idx1-ubyte  \n",
            "   creating: data/mnist/processed/\n",
            "  inflating: data/mnist/processed/training.pt  \n",
            "  inflating: data/mnist/processed/test.pt  \n",
            "   creating: data/mnist/MNIST/\n",
            "   creating: data/mnist/MNIST/raw/\n",
            "  inflating: data/mnist/MNIST/raw/train-images-idx3-ubyte  \n",
            "  inflating: data/mnist/MNIST/raw/train-labels-idx1-ubyte  \n",
            "  inflating: data/mnist/MNIST/raw/t10k-images-idx3-ubyte  \n",
            "  inflating: data/mnist/MNIST/raw/t10k-labels-idx1-ubyte  \n",
            "   creating: data/mnist/MNIST/processed/\n",
            "  inflating: data/mnist/MNIST/processed/training.pt  \n",
            "  inflating: data/mnist/MNIST/processed/test.pt  \n",
            "   creating: data/cifar10/\n",
            "  inflating: data/cifar10/cifar-10-python.tar.gz  \n",
            "   creating: data/cifar10/cifar-10-batches-py/\n",
            "  inflating: data/cifar10/cifar-10-batches-py/data_batch_4  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/readme.html  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/test_batch  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/data_batch_3  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/batches.meta  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/data_batch_2  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/data_batch_5  \n",
            "  inflating: data/cifar10/cifar-10-batches-py/data_batch_1  \n",
            "  inflating: dlc_practical_4_embryo.py  \n",
            "  inflating: dlc_practical_prologue.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvpz_3qnOHMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "# TO LOAD MNIST DATASET\n",
        "from dlc_practical_prologue import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBi3lhSTOO4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a48e19c4-cb5e-42b2-851e-c1f7d1ad0a14"
      },
      "source": [
        "data = load_data(one_hot_labels=True,normalize=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Using MNIST\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "** Reduce the data-set (use --full for the full thing)\n",
            "** Use 1000 train and 1000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NE7f8WGP3U9",
        "colab_type": "text"
      },
      "source": [
        "\\begin{aligned}\n",
        "&\\tanh (x)\n",
        "\\\\~\\\\\n",
        "&\\frac{d \\tanh (x)}{d x}\n",
        "\\\\~\\\\\n",
        "&\\|t-v\\|^{2}\n",
        "\\\\~\\\\\n",
        "&2 *(t-v)\n",
        "\\end{aligned}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtZHUtz6OeQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HELPER FUNCTIONS\n",
        "def sigma(inputs):\n",
        "    return torch.tanh(inputs)\n",
        "\n",
        "def dsigma(inputs):\n",
        "    return 1-torch.pow(sigma(inputs),2)\n",
        "\n",
        "def loss(v,t):\n",
        "    return torch.pow((v-t),2).sum()\n",
        "\n",
        "def dloss(v,t):\n",
        "    return 2*(v-t)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RCE6KacO_Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_params(train_images,hidden_dim=50,out_dim=10,std = 1e-6):\n",
        "    w1 = torch.empty((hidden_dim,train_images.size(1))).normal_(0,std)\n",
        "    b1 = torch.empty((hidden_dim,1)).normal_(0,std)\n",
        "\n",
        "    w2 = torch.empty((out_dim,hidden_dim)).normal_(0,std)\n",
        "    b2 = torch.empty((out_dim,1)).normal_(0,std)\n",
        "\n",
        "    dl_w1 = torch.empty_like(w1)\n",
        "    dl_b1 = torch.empty_like(b1)\n",
        "\n",
        "    dl_w2 = torch.empty_like(w2)\n",
        "    dl_b2 = torch.empty_like(b2)\n",
        "\n",
        "    return w1,b1,w2,b2,dl_w1,dl_b1,dl_w2,dl_b2\n",
        "  \n",
        "  \n",
        "def forward_pass(w1,b1,w2,b2,x):\n",
        "    s1 = torch.add(torch.mm(w1,x),b1)\n",
        "    x1 = sigma(s1)\n",
        "\n",
        "    s2 = torch.add(torch.mm(w2,x1),b2)\n",
        "    x2 = sigma(s2)\n",
        "\n",
        "    return x,s1,x1,s2,x2\n",
        "\n",
        "    \n",
        "    \n",
        "def backward_pass(w1,b1,w2,b2,t,x,s1,x1,s2,x2,dl_dw1,dl_db1,dl_dw2,dl_db2):\n",
        "    dl_dx2 = dloss(x2,t)\n",
        "    dl_ds2 = dl_dx2*dsigma(s2)\n",
        "\n",
        "    dl_dw2.add_(torch.mm(dl_ds2,x1.view(1,-1)))\n",
        "    dl_db2.add_(dl_ds2)\n",
        "\n",
        "    dl_dx1 = torch.mm(w2.T,dl_ds2)\n",
        "    dl_ds1 = dl_dx1*dsigma(s1)\n",
        "\n",
        "    dl_dw1.add_(torch.mm(dl_ds1,x.view(1,-1)))\n",
        "    dl_db1.add_(dl_ds1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCaNt3CNPEz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "20ebb231-9bb2-4ec2-f08c-813cf2499f15"
      },
      "source": [
        "train_images,train_labels,test_images,test_labels = data\n",
        "\n",
        "w1,b1,w2,b2,dl_dw1,dl_db1,dl_dw2,dl_db2 = get_params(train_images,hidden_dim=50,out_dim=10)\n",
        "\n",
        "train_labels,test_labels = train_labels * 0.9,test_labels * 0.9\n",
        "train_images,train_labels = train_images * 0.9,train_labels * 0.9\n",
        "\n",
        "train_size = len(train_images)\n",
        "test_size = len(test_images)\n",
        "\n",
        "lr = 1e-1 / train_size\n",
        "epoch = 1000\n",
        "\n",
        "for i in range(epoch):\n",
        "    dl_dw1.zero_()\n",
        "    dl_db1.zero_()\n",
        "    dl_dw2.zero_()\n",
        "    dl_db2.zero_()\n",
        "\n",
        "    correct_count = 0\n",
        "    test_correct_count = 0\n",
        "\n",
        "    for image,labels in zip(train_images,train_labels):\n",
        "        x,s1,x1,s2,x2 = forward_pass(w1,b1,w2,b2,image.view(-1,1))\n",
        "        backward_pass(w1,b1,w2,b2,labels.view(-1,1),image.view(-1,1),s1,x1,s2,x2,dl_dw1,dl_db1,dl_dw2,dl_db2)\n",
        "\n",
        "    w1 = w1 -  lr * dl_dw1\n",
        "    b1 = b1 -  lr * dl_db1\n",
        "    w2 = w2 -  lr * dl_dw2\n",
        "    b2 = b2 -  lr * dl_db2\n",
        "\n",
        "    for img,lbl in zip(train_images,train_labels):\n",
        "        _,_,_,_,x2 = forward_pass(w1,b1,w2,b2,img.view(-1,1))\n",
        "        if x2.max(0)[1].item()==lbl.max(0)[1].item():\n",
        "            correct_count +=1\n",
        "\n",
        "    for t_img,t_lbl in zip(test_images,test_labels):\n",
        "        _,_,_,_,t_x2 = forward_pass(w1,b1,w2,b2,t_img.view(-1,1))\n",
        "        if t_x2.max(0)[1].item()==t_lbl.view(-1,1).max(0)[1].item():\n",
        "            test_correct_count +=1\n",
        "    \n",
        "    if i%100 == 0:\n",
        "        print('Epoch: {}, Train Accuracy(Error Rate): {:.02f}({:.02f}) , Test Accuracy(Error Rate): {:.02f}({:.02f})'.format(i,\\\n",
        "            correct_count/train_size,1-(correct_count/train_size),test_correct_count/test_size,1-(test_correct_count/test_size)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Train Accuracy(Error Rate): 0.12(0.88) , Test Accuracy(Error Rate): 0.10(0.90)\n",
            "Epoch: 100, Train Accuracy(Error Rate): 0.78(0.22) , Test Accuracy(Error Rate): 0.72(0.28)\n",
            "Epoch: 200, Train Accuracy(Error Rate): 0.91(0.09) , Test Accuracy(Error Rate): 0.80(0.20)\n",
            "Epoch: 300, Train Accuracy(Error Rate): 0.95(0.05) , Test Accuracy(Error Rate): 0.83(0.17)\n",
            "Epoch: 400, Train Accuracy(Error Rate): 0.96(0.04) , Test Accuracy(Error Rate): 0.82(0.18)\n",
            "Epoch: 500, Train Accuracy(Error Rate): 0.97(0.03) , Test Accuracy(Error Rate): 0.85(0.15)\n",
            "Epoch: 600, Train Accuracy(Error Rate): 0.98(0.02) , Test Accuracy(Error Rate): 0.84(0.16)\n",
            "Epoch: 700, Train Accuracy(Error Rate): 0.99(0.01) , Test Accuracy(Error Rate): 0.85(0.15)\n",
            "Epoch: 800, Train Accuracy(Error Rate): 0.99(0.01) , Test Accuracy(Error Rate): 0.84(0.16)\n",
            "Epoch: 900, Train Accuracy(Error Rate): 0.99(0.01) , Test Accuracy(Error Rate): 0.85(0.15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWXc6JefPeoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}