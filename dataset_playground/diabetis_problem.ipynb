{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "print(diabetes['feature_names'])\n",
    "data = diabetes['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat((pd.DataFrame(data),pd.DataFrame(diabetes['target'])),axis=1)\n",
    "dataset.columns= ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 11), (353, 11))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 0.2\n",
    "\n",
    "\n",
    "final_data = dataset.values\n",
    "np.random.shuffle(final_data)\n",
    "train_data = final_data[:int(len(final_data)*train_size)]\n",
    "test_data = final_data[:int(len(final_data)*(1-train_size))]\n",
    "\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 10), (88, 1), (353, 10), (353, 1))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[:,:-1]\n",
    "y_train = train_data[:,-1:]\n",
    "\n",
    "\n",
    "X_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1:]\n",
    "\n",
    "\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression():\n",
    "    def __init__(self,train_data,train_labels,lr=0.01,batch_size=None,epoch=10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def hypothesis(self,x):\n",
    "        return np.dot(x.T,self.params)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return np.dot(x,self.params[1:])+self.params[0]\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return np.mean(np.sum(y_pred-y))#+np.sum(np.square(self.params))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        hassian = np.linalg.inv(np.dot(x.T,x))\n",
    "        return np.dot(hassian,np.dot(x.T,val))\n",
    "    \n",
    "    def train_st(self):\n",
    "        for i in range(self.epoch):\n",
    "            for train,label in zip(self.train_data,self.train_labels):\n",
    "                train = train.reshape(-1,1)\n",
    "                label = label.reshape(-1,1)\n",
    "                y_pred = self.hypothesis(train)\n",
    "                co = self.cost(label,y_pred)\n",
    "                grad = self.gradient(label,y_pred,train)\n",
    "\n",
    "\n",
    "                self.params += grad\n",
    "\n",
    "                print('Epoch : {}  , Loss : {} '.format(i,co))\n",
    "                \n",
    "    def train_ba(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.hypothesis(self.train_data.T)\n",
    "            co = self.cost(self.train_labels,y_pred)\n",
    "            grad = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "\n",
    "\n",
    "            self.params += self.lr*grad\n",
    "\n",
    "            print('Epoch : {}  , Loss : {} '.format(i,co))\n",
    "                \n",
    "    def evaluate(self,x_test,y_test):\n",
    "        rmse =np.sqrt(np.mean(np.square(np.subtract(self.predict(x_test),y_test))))\n",
    "        return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear_regression(X_train,y_train,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  , Loss : -12776.0 \n",
      "Epoch : 1  , Loss : -12903.76 \n",
      "Epoch : 2  , Loss : -13032.797600000002 \n",
      "Epoch : 3  , Loss : -13163.125576 \n",
      "Epoch : 4  , Loss : -13294.756831759998 \n",
      "Epoch : 5  , Loss : -13427.7044000776 \n",
      "Epoch : 6  , Loss : -13561.981444078376 \n",
      "Epoch : 7  , Loss : -13697.60125851916 \n",
      "Epoch : 8  , Loss : -13834.577271104352 \n",
      "Epoch : 9  , Loss : -13972.923043815397 \n",
      "Epoch : 10  , Loss : -14112.652274253549 \n",
      "Epoch : 11  , Loss : -14253.778796996085 \n",
      "Epoch : 12  , Loss : -14396.316584966044 \n",
      "Epoch : 13  , Loss : -14540.279750815705 \n",
      "Epoch : 14  , Loss : -14685.682548323864 \n",
      "Epoch : 15  , Loss : -14832.539373807102 \n",
      "Epoch : 16  , Loss : -14980.864767545172 \n",
      "Epoch : 17  , Loss : -15130.673415220625 \n",
      "Epoch : 18  , Loss : -15281.98014937283 \n",
      "Epoch : 19  , Loss : -15434.79995086656 \n",
      "Epoch : 20  , Loss : -15589.147950375223 \n",
      "Epoch : 21  , Loss : -15745.039429878978 \n",
      "Epoch : 22  , Loss : -15902.489824177766 \n",
      "Epoch : 23  , Loss : -16061.514722419546 \n",
      "Epoch : 24  , Loss : -16222.129869643742 \n",
      "Epoch : 25  , Loss : -16384.351168340178 \n",
      "Epoch : 26  , Loss : -16548.19468002358 \n",
      "Epoch : 27  , Loss : -16713.676626823813 \n",
      "Epoch : 28  , Loss : -16880.813393092052 \n",
      "Epoch : 29  , Loss : -17049.621527022973 \n",
      "Epoch : 30  , Loss : -17220.117742293205 \n",
      "Epoch : 31  , Loss : -17392.318919716134 \n",
      "Epoch : 32  , Loss : -17566.242108913295 \n",
      "Epoch : 33  , Loss : -17741.90453000243 \n",
      "Epoch : 34  , Loss : -17919.323575302453 \n",
      "Epoch : 35  , Loss : -18098.516811055477 \n",
      "Epoch : 36  , Loss : -18279.501979166034 \n",
      "Epoch : 37  , Loss : -18462.296998957696 \n",
      "Epoch : 38  , Loss : -18646.919968947273 \n",
      "Epoch : 39  , Loss : -18833.389168636742 \n",
      "Epoch : 40  , Loss : -19021.72306032311 \n",
      "Epoch : 41  , Loss : -19211.940290926344 \n",
      "Epoch : 42  , Loss : -19404.059693835607 \n",
      "Epoch : 43  , Loss : -19598.10029077396 \n",
      "Epoch : 44  , Loss : -19794.081293681702 \n",
      "Epoch : 45  , Loss : -19992.022106618522 \n",
      "Epoch : 46  , Loss : -20191.94232768471 \n",
      "Epoch : 47  , Loss : -20393.86175096155 \n",
      "Epoch : 48  , Loss : -20597.800368471166 \n",
      "Epoch : 49  , Loss : -20803.778372155877 \n",
      "Epoch : 50  , Loss : -21011.816155877437 \n",
      "Epoch : 51  , Loss : -21221.93431743621 \n",
      "Epoch : 52  , Loss : -21434.153660610573 \n",
      "Epoch : 53  , Loss : -21648.49519721668 \n",
      "Epoch : 54  , Loss : -21864.980149188843 \n",
      "Epoch : 55  , Loss : -22083.629950680734 \n",
      "Epoch : 56  , Loss : -22304.466250187543 \n",
      "Epoch : 57  , Loss : -22527.510912689417 \n",
      "Epoch : 58  , Loss : -22752.78602181631 \n",
      "Epoch : 59  , Loss : -22980.313882034472 \n",
      "Epoch : 60  , Loss : -23210.11702085482 \n",
      "Epoch : 61  , Loss : -23442.218191063366 \n",
      "Epoch : 62  , Loss : -23676.640372974 \n",
      "Epoch : 63  , Loss : -23913.40677670374 \n",
      "Epoch : 64  , Loss : -24152.54084447078 \n",
      "Epoch : 65  , Loss : -24394.066252915483 \n",
      "Epoch : 66  , Loss : -24638.00691544464 \n",
      "Epoch : 67  , Loss : -24884.386984599085 \n",
      "Epoch : 68  , Loss : -25133.23085444508 \n",
      "Epoch : 69  , Loss : -25384.563162989525 \n",
      "Epoch : 70  , Loss : -25638.408794619423 \n",
      "Epoch : 71  , Loss : -25894.79288256562 \n",
      "Epoch : 72  , Loss : -26153.740811391275 \n",
      "Epoch : 73  , Loss : -26415.27821950519 \n",
      "Epoch : 74  , Loss : -26679.43100170024 \n",
      "Epoch : 75  , Loss : -26946.225311717244 \n",
      "Epoch : 76  , Loss : -27215.687564834414 \n",
      "Epoch : 77  , Loss : -27487.84444048276 \n",
      "Epoch : 78  , Loss : -27762.72288488759 \n",
      "Epoch : 79  , Loss : -28040.350113736466 \n",
      "Epoch : 80  , Loss : -28320.75361487383 \n",
      "Epoch : 81  , Loss : -28603.961151022566 \n",
      "Epoch : 82  , Loss : -28890.000762532793 \n",
      "Epoch : 83  , Loss : -29178.900770158118 \n",
      "Epoch : 84  , Loss : -29470.689777859698 \n",
      "Epoch : 85  , Loss : -29765.3966756383 \n",
      "Epoch : 86  , Loss : -30063.050642394683 \n",
      "Epoch : 87  , Loss : -30363.68114881863 \n",
      "Epoch : 88  , Loss : -30667.317960306817 \n",
      "Epoch : 89  , Loss : -30973.991139909886 \n",
      "Epoch : 90  , Loss : -31283.731051308983 \n",
      "Epoch : 91  , Loss : -31596.568361822076 \n",
      "Epoch : 92  , Loss : -31912.53404544029 \n",
      "Epoch : 93  , Loss : -32231.659385894694 \n",
      "Epoch : 94  , Loss : -32553.97597975364 \n",
      "Epoch : 95  , Loss : -32879.51573955117 \n",
      "Epoch : 96  , Loss : -33208.31089694669 \n",
      "Epoch : 97  , Loss : -33540.39400591616 \n",
      "Epoch : 98  , Loss : -33875.79794597532 \n",
      "Epoch : 99  , Loss : -34214.55592543507 \n"
     ]
    }
   ],
   "source": [
    "linear.train_ba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418.33142377463145"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.3408481020742"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -247.64129684],\n",
       "       [   19.59231086],\n",
       "       [  511.89756907],\n",
       "       [  -31.5311845 ],\n",
       "       [ -828.90206824],\n",
       "       [ 2213.46389175],\n",
       "       [-1702.97435631],\n",
       "       [ -393.78816749],\n",
       "       [ -555.88099134],\n",
       "       [-1807.5106226 ],\n",
       "       [  239.14005704]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
