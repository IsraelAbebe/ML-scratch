{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.6\n",
    "test_size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data['data']\n",
    "target = data['target'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.hstack((dataset,target))\n",
    "np.random.shuffle(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "145                5.0               3.5                1.3               0.3   \n",
       "146                6.1               2.8                4.7               1.2   \n",
       "\n",
       "     target  \n",
       "145     0.0  \n",
       "146     1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data = pd.DataFrame(final_data)\n",
    "pd_data.columns= ['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)','target']\n",
    "pd_data = pd_data[(pd_data['target']==0) | (pd_data['target']==1)]\n",
    "pd_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 5), (40, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd_data.values\n",
    "\n",
    "train_data = final_data[:int(len(final_data)*train_size)]\n",
    "test_data = final_data[:int(len(final_data)*test_size)]\n",
    "\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 4), (60, 1), (40, 4), (40, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data[:,:-1]\n",
    "y_train = train_data[:,-1:]\n",
    "\n",
    "\n",
    "X_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1:]\n",
    "\n",
    "\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(y,y_pred,x):\n",
    "    return np.dot(x.T,(y-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_grad(x):\n",
    "    return sigmoid(x)(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,y_pred):\n",
    "    cost = -np.mean((y*np.log(y_pred))+((1-y)*(np.log(1-y_pred))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0  Loss: 0.6931471805599454\n",
      "Epoch :  10  Loss: 0.4664291766402609\n",
      "Epoch :  20  Loss: 0.35583248173654897\n",
      "Epoch :  30  Loss: 0.28388961752230385\n",
      "Epoch :  40  Loss: 0.234643686110827\n",
      "Epoch :  50  Loss: 0.1993116173297633\n",
      "Epoch :  60  Loss: 0.1729357182569546\n",
      "Epoch :  70  Loss: 0.1525904029979892\n",
      "Epoch :  80  Loss: 0.1364677560678673\n",
      "Epoch :  90  Loss: 0.12340218344669138\n",
      "Epoch :  100  Loss: 0.1126135738988026\n",
      "Epoch :  110  Loss: 0.10356252701739771\n",
      "Epoch :  120  Loss: 0.0958653693310874\n",
      "Epoch :  130  Loss: 0.08924237760294493\n",
      "Epoch :  140  Loss: 0.08348516090185978\n",
      "Epoch :  150  Loss: 0.07843548858218807\n",
      "Epoch :  160  Loss: 0.07397117581050786\n",
      "Epoch :  170  Loss: 0.069996446565363\n",
      "Epoch :  180  Loss: 0.06643521117363786\n",
      "Epoch :  190  Loss: 0.06322628553865252\n",
      "Epoch :  200  Loss: 0.060319931390357594\n",
      "Epoch :  210  Loss: 0.057675312585096665\n",
      "Epoch :  220  Loss: 0.05525859775614366\n",
      "Epoch :  230  Loss: 0.05304152631224878\n",
      "Epoch :  240  Loss: 0.05100031146064823\n",
      "Epoch :  250  Loss: 0.04911479167015357\n",
      "Epoch :  260  Loss: 0.04736776754531564\n",
      "Epoch :  270  Loss: 0.04574447865937016\n",
      "Epoch :  280  Loss: 0.04423218715842476\n",
      "Epoch :  290  Loss: 0.042819843622909436\n",
      "Epoch :  300  Loss: 0.04149781688313516\n",
      "Epoch :  310  Loss: 0.0402576739851496\n",
      "Epoch :  320  Loss: 0.039091999798167444\n",
      "Epoch :  330  Loss: 0.03799424819267661\n",
      "Epoch :  340  Loss: 0.036958618539208773\n",
      "Epoch :  350  Loss: 0.03597995265009254\n",
      "Epoch :  360  Loss: 0.035053648329551906\n",
      "Epoch :  370  Loss: 0.03417558649662233\n",
      "Epoch :  380  Loss: 0.03334206946220068\n",
      "Epoch :  390  Loss: 0.03254976842110281\n",
      "Epoch :  400  Loss: 0.031795678595343234\n",
      "Epoch :  410  Loss: 0.03107708076051615\n",
      "Epoch :  420  Loss: 0.030391508121471542\n",
      "Epoch :  430  Loss: 0.02973671769025687\n",
      "Epoch :  440  Loss: 0.029110665468993973\n",
      "Epoch :  450  Loss: 0.028511484860978053\n",
      "Epoch :  460  Loss: 0.02793746783095572\n",
      "Epoch :  470  Loss: 0.027387048415007664\n",
      "Epoch :  480  Loss: 0.026858788245415523\n",
      "Epoch :  490  Loss: 0.02635136380921852\n",
      "Epoch :  500  Loss: 0.02586355520312588\n",
      "Epoch :  510  Loss: 0.025394236183837727\n",
      "Epoch :  520  Loss: 0.024942365343063357\n",
      "Epoch :  530  Loss: 0.024506978261740146\n",
      "Epoch :  540  Loss: 0.024087180519063035\n",
      "Epoch :  550  Loss: 0.023682141449657777\n",
      "Epoch :  560  Loss: 0.02329108855716811\n",
      "Epoch :  570  Loss: 0.022913302505151213\n",
      "Epoch :  580  Loss: 0.022548112616879976\n",
      "Epoch :  590  Loss: 0.02219489282475453\n",
      "Epoch :  600  Loss: 0.02185305801778831\n",
      "Epoch :  610  Loss: 0.021522060742272628\n",
      "Epoch :  620  Loss: 0.021201388216416994\n",
      "Epoch :  630  Loss: 0.020890559624655605\n",
      "Epoch :  640  Loss: 0.020589123661527695\n",
      "Epoch :  650  Loss: 0.020296656298682884\n",
      "Epoch :  660  Loss: 0.020012758751717687\n",
      "Epoch :  670  Loss: 0.019737055626285874\n",
      "Epoch :  680  Loss: 0.01946919322530787\n",
      "Epoch :  690  Loss: 0.01920883800117897\n",
      "Epoch :  700  Loss: 0.018955675138689055\n",
      "Epoch :  710  Loss: 0.018709407255952746\n",
      "Epoch :  720  Loss: 0.018469753212039645\n",
      "Epoch :  730  Loss: 0.018236447011216853\n",
      "Epoch :  740  Loss: 0.018009236794790568\n",
      "Epoch :  750  Loss: 0.017787883912482705\n",
      "Epoch :  760  Loss: 0.017572162066114776\n",
      "Epoch :  770  Loss: 0.017361856519113258\n",
      "Epoch :  780  Loss: 0.017156763366006713\n",
      "Epoch :  790  Loss: 0.016956688856667283\n",
      "Epoch :  800  Loss: 0.016761448770568087\n",
      "Epoch :  810  Loss: 0.016570867836788353\n",
      "Epoch :  820  Loss: 0.0163847791959099\n",
      "Epoch :  830  Loss: 0.016203023900315677\n",
      "Epoch :  840  Loss: 0.01602545044972869\n",
      "Epoch :  850  Loss: 0.015851914359125106\n",
      "Epoch :  860  Loss: 0.015682277756416868\n",
      "Epoch :  870  Loss: 0.0155164090075379\n",
      "Epoch :  880  Loss: 0.015354182366778914\n",
      "Epoch :  890  Loss: 0.01519547765040818\n",
      "Epoch :  900  Loss: 0.015040179931788212\n",
      "Epoch :  910  Loss: 0.014888179256353311\n",
      "Epoch :  920  Loss: 0.014739370374954123\n",
      "Epoch :  930  Loss: 0.014593652494201999\n",
      "Epoch :  940  Loss: 0.01445092904256162\n",
      "Epoch :  950  Loss: 0.014311107451043676\n",
      "Epoch :  960  Loss: 0.014174098947445455\n",
      "Epoch :  970  Loss: 0.014039818363171353\n",
      "Epoch :  980  Loss: 0.013908183951745173\n",
      "Epoch :  990  Loss: 0.013779117218195764\n"
     ]
    }
   ],
   "source": [
    "dummy_train = np.hstack((np.ones((len(train_data),1)),X_train))\n",
    "weight = np.zeros((len(dummy_train[0]),1))\n",
    "lr = 0.001\n",
    "epoch = 1000\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    y_pred = sigmoid(np.dot(dummy_train,weight))\n",
    "    co = cost(y_train,y_pred)\n",
    "    gra = gradient(y_train,y_pred,dummy_train)\n",
    "    weight += lr*gra\n",
    "    \n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print('Epoch : ',i,' Loss:',co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30373647],\n",
       "       [-0.47417418],\n",
       "       [-1.76281071],\n",
       "       [ 2.74306895],\n",
       "       [ 1.23296972]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w):\n",
    "    sig = sigmoid(np.dot(x,w[1:])+w[0])\n",
    "    sig[sig > 0.5] = 1\n",
    "    sig[sig < 0.5] = 0\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predict(X_test,weight),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lr=0.01,batch_size=None,epoch=10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.sigmoid(np.dot(self.train_data,self.params))\n",
    "            loss = self.cost(self.train_labels,y_pred)\n",
    "            \n",
    "            gra = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "            \n",
    "            self.params -= self.lr*gra\n",
    "            \n",
    "            if i%10 == 0 or i == self.epoch-1:\n",
    "                print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result >= 0.5 ] = 1\n",
    "        result[result < 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = logisticregression(X_train,y_train,epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  Loss: 0.6931471805599454\n",
      "Epoch : 9  Loss: 0.035442194456427614\n"
     ]
    }
   ],
   "source": [
    "logistic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
